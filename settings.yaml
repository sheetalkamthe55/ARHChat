server:
  env_name: ${APP_ENV:prod}
  host: ${HOST:0.0.0.0}
  port: ${PORT:8505}
  cors:
    enabled: true
    allow_origins: ["*"]
    allow_methods: ["*"]
    allow_headers: ["*"]
  auth:
    enabled: false
    # python -c 'import base64; print("Basic " + base64.b64encode("secret:key".encode()).decode())'
    secret: "Basic c2VjcmV0OmtleQ=="

rag:
  rerank:
    enabled: false
    model: "BAAI/bge-reranker-base"
    top_n: 3
  #not used, since did not find any improvement in the results

llm:
  inference_server_url: "http://localhost:8009/v1"
  llm_name: "no-model"
  api_key: "no-key"
  stream: true

embeddings:
  embed_name: "intfloat/e5-base-v2"
  inference_server_url: "http://localhost:8009/v1"
  api_key: "no-key"

qdrant:
  url: "http://localhost:6333"
  api_key: "None"
  vector_collectionname: "ARH_Tool"
  search_type: "mmr"
  lambda_mult: 0.25
  similarity_top_k: 3

mongodb:
  url: "mongodb://localhost:27017"
  db_name: "ARH_chatbot"
  history_collectionname: "chat_history"

ui:
  # enabled: true
  app_title: "Architecture Refactoring AI Helper"
  question_system_prompt: >
    Given a chat history and a follow-up question, rephrase the follow-up question to be a standalone question.
    Do NOT answer the question, just reformulate it if needed, otherwise return it as is. 
    Only return the final standalone question.
  rag_system_prompt: >
    You are a chatbot specialized in answering questions in context concisely. 
    If you cannot find the answer to a query in the provided context, say you cannot answer or provide related information from the context. 
    Do not make up answers that are not contained in the context.: \Context: {context}


